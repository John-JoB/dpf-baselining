{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-21T09:32:08.340523Z",
     "start_time": "2025-05-21T09:31:59.901401Z"
    }
   },
   "source": [
    "import torch\n",
    "import pydpf\n",
    "import model\n",
    "import pathlib\n",
    "from training_loop import train\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:32:08.357826Z",
     "start_time": "2025-05-21T09:32:08.340523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")   \n",
    "data_path = pathlib.Path('.').parent.absolute().joinpath('data.csv')\n",
    "experiment_cuda_rng = torch.Generator(device).manual_seed(0)\n",
    "experiment_cpu_rng = torch.Generator().manual_seed(0)\n",
    "DPF_type = 'Optimal Transport'\n",
    "n_repeats = 10"
   ],
   "id": "9bf63c931b6c561c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:32:08.406109Z",
     "start_time": "2025-05-21T09:32:08.402424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_SSM():\n",
    "    alpha = torch.nn.Parameter(torch.rand((1,1), device=device, generator=experiment_cuda_rng), requires_grad=True)\n",
    "    sigma = torch.nn.Parameter(torch.rand((1,1), device=device, generator=experiment_cuda_rng)*5, requires_grad=True)\n",
    "    beta = torch.nn.Parameter(torch.rand((1,), device=device, generator=experiment_cuda_rng)*2, requires_grad=True)\n",
    "    return model.make_SSM(sigma, alpha, beta, device, experiment_cuda_rng), alpha, beta, sigma"
   ],
   "id": "b162a2bcba0f12bd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T09:32:08.414535Z",
     "start_time": "2025-05-21T09:32:08.410393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_DPF(SSM):\n",
    "    if DPF_type == 'DPF':\n",
    "        return pydpf.DPF(SSM=SSM, resampling_generator=experiment_cuda_rng)\n",
    "    if DPF_type == 'Soft':\n",
    "        return pydpf.SoftDPF(SSM=SSM, resampling_generator=experiment_cuda_rng)\n",
    "    if DPF_type == 'Stop-Gradient':\n",
    "        return pydpf.StopGradientDPF(SSM=SSM, resampling_generator=experiment_cuda_rng)\n",
    "    if DPF_type == 'Marginal Stop-Gradient':\n",
    "        return pydpf.MarginalStopGradientDPF(SSM=SSM, resampling_generator=experiment_cuda_rng)\n",
    "    if DPF_type == 'Optimal Transport':\n",
    "        return pydpf.OptimalTransportDPF(SSM=SSM, regularisation=1., transport_gradient_clip=1.)\n",
    "    if DPF_type == 'Kernel':\n",
    "        kernel = pydpf.KernelMixture([('Gaussian', 1)], gradient_estimator='reparameterisation', generator=experiment_cuda_rng)\n",
    "        return pydpf.KernelDPF(SSM=SSM, kernel=kernel)\n",
    "    raise ValueError('DPF_type should be one of the allowed options')"
   ],
   "id": "8ca753311dcf1186",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T11:01:24.207378Z",
     "start_time": "2025-05-21T09:32:08.418484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ELBOs = np.empty(n_repeats)\n",
    "alphas = np.empty(n_repeats)\n",
    "betas = np.empty(n_repeats)\n",
    "sigmas = np.empty(n_repeats)\n",
    "\n",
    "for n in range(n_repeats):\n",
    "    experiment_cuda_rng = torch.Generator(device).manual_seed(n*10)\n",
    "    generation_rng = torch.Generator(device).manual_seed(n*10)\n",
    "    true_SSM = model.make_SSM(torch.tensor([[1.]], device=device), torch.tensor([[0.91]], device=device), torch.tensor([0.5], device=device), device, generation_rng)\n",
    "    pydpf.simulate_and_save(data_path, SSM=true_SSM, time_extent=1000, n_trajectories=500, batch_size=100, device=device, by_pass_ask=True)\n",
    "    SSM, alpha, beta, sigma = get_SSM()\n",
    "    dpf = get_DPF(SSM)\n",
    "    if DPF_type == 'Kernel':\n",
    "        opt = torch.optim.SGD([{'params':[alpha], 'lr':0.05}, {'params':[beta], 'lr':0.1}, {'params':[sigma], 'lr':0.25}, {'params':dpf.resampler.mixture.parameters(), 'lr':0.1}], lr=0.2, momentum=0.9, nesterov=True)\n",
    "    else:\n",
    "        opt = torch.optim.SGD([{'params':[alpha], 'lr':0.05}, {'params':[beta], 'lr':0.1}, {'params':[sigma], 'lr':0.25}], lr=0.2, momentum=0.9, nesterov=True)\n",
    "    opt_schedule = torch.optim.lr_scheduler.ExponentialLR(opt, 0.95)\n",
    "    dataset = pydpf.StateSpaceDataset(data_path, state_prefix='state', device=device)\n",
    "    _, ELBO = train(dpf, opt, dataset, 20, (100, 100, 100), (30, 100, 100), (0.5, 0.25, 0.25), 1., experiment_cpu_rng, target='ELBO', time_extent=100, lr_scheduler=opt_schedule)\n",
    "    print(alpha)\n",
    "    print(beta)\n",
    "    print(sigma)\n",
    "    ELBOs[n] = ELBO\n",
    "    alphas[n] = alpha\n",
    "    betas[n] = beta\n",
    "    sigmas[n] = sigma"
   ],
   "id": "7ecf40ae6833654",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done                  \n",
      "\n",
      "epoch 1/20, train loss: 1.4090716695785523, validation MSE: 15.979748344421386, validation ELBO: 140.04453125\n",
      "epoch 2/20, train loss: 1.2165849351882934, validation MSE: 15.440218544006347, validation ELBO: 111.38011779785157\n",
      "epoch 3/20, train loss: 1.1700194358825684, validation MSE: 20.240576934814452, validation ELBO: 133.5508590698242\n",
      "epoch 4/20, train loss: 1.2429206466674805, validation MSE: 20.063731384277343, validation ELBO: 122.19822540283204\n",
      "epoch 5/20, train loss: 1.5601392793655395, validation MSE: 7.354516983032227, validation ELBO: 199.19228515625\n",
      "epoch 6/20, train loss: 1.610203514099121, validation MSE: 18.709768295288086, validation ELBO: 147.14799041748046\n",
      "epoch 7/20, train loss: 1.3821129179000855, validation MSE: 16.330819511413573, validation ELBO: 136.7983184814453\n",
      "epoch 8/20, train loss: 1.2200438976287842, validation MSE: 14.761037063598632, validation ELBO: 118.10815887451172\n",
      "epoch 9/20, train loss: 1.5086664581298828, validation MSE: 5.897547340393066, validation ELBO: 219.3572998046875\n",
      "epoch 10/20, train loss: 2.0519359636306764, validation MSE: 5.012334823608398, validation ELBO: 181.0410125732422\n",
      "epoch 11/20, train loss: 1.5083818292617799, validation MSE: 2.4347784996032713, validation ELBO: 130.07574768066405\n",
      "epoch 12/20, train loss: 1.2181560325622558, validation MSE: 2.6183292865753174, validation ELBO: 125.62173461914062\n",
      "epoch 13/20, train loss: 1.1780520677566528, validation MSE: 2.375078010559082, validation ELBO: 121.9472900390625\n",
      "epoch 14/20, train loss: 1.093477041721344, validation MSE: 1.5017551898956298, validation ELBO: 108.25315856933594\n",
      "epoch 15/20, train loss: 0.9927181100845337, validation MSE: 1.2941123247146606, validation ELBO: 105.00395050048829\n",
      "epoch 16/20, train loss: 1.009597430229187, validation MSE: 3.2828031539916993, validation ELBO: 154.32365875244142\n",
      "epoch 17/20, train loss: 1.322353391647339, validation MSE: 2.708899974822998, validation ELBO: 133.16020965576172\n",
      "epoch 18/20, train loss: 1.2465215253829955, validation MSE: 2.448599338531494, validation ELBO: 127.80952758789063\n",
      "epoch 19/20, train loss: 1.1832269525527954, validation MSE: 2.436541748046875, validation ELBO: 122.62472839355469\n",
      "epoch 20/20, train loss: 1.1351462173461915, validation MSE: 2.1349314212799073, validation ELBO: 118.46698455810547\n",
      "\n",
      "test MSE: 1.3705276012420655, test ELBO: 113.58100280761718\n",
      "Parameter containing:\n",
      "tensor([[0.8688]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4873], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.3839]], device='cuda:0', requires_grad=True)\n",
      "Done                  \n",
      "\n",
      "epoch 1/20, train loss: 1.1365415692329406, validation MSE: 9.257946395874024, validation ELBO: 113.58214721679687\n",
      "epoch 2/20, train loss: 1.1211103320121765, validation MSE: 8.288290214538574, validation ELBO: 111.98963317871093\n",
      "epoch 3/20, train loss: 1.099174795150757, validation MSE: 6.816631221771241, validation ELBO: 106.9836181640625\n",
      "epoch 4/20, train loss: 1.6137600612640381, validation MSE: 3.50439510345459, validation ELBO: 146.2249298095703\n",
      "epoch 5/20, train loss: 1.3640151643753051, validation MSE: 3.144899034500122, validation ELBO: 129.88259887695312\n",
      "epoch 6/20, train loss: 1.2887066459655763, validation MSE: 2.649177980422974, validation ELBO: 123.97198486328125\n",
      "epoch 7/20, train loss: 1.1884052467346191, validation MSE: 1.5834480285644532, validation ELBO: 107.19500732421875\n",
      "epoch 8/20, train loss: 1.0569132041931153, validation MSE: 1.7650604009628297, validation ELBO: 111.07911071777343\n",
      "epoch 9/20, train loss: 1.20413423538208, validation MSE: 3.3657379150390625, validation ELBO: 128.39537963867187\n",
      "epoch 10/20, train loss: 1.3306127214431762, validation MSE: 3.3994823455810548, validation ELBO: 132.3590545654297\n",
      "epoch 11/20, train loss: 1.2828652381896972, validation MSE: 2.352468490600586, validation ELBO: 118.82882080078124\n",
      "epoch 12/20, train loss: 1.1372984290122985, validation MSE: 1.5810427904129027, validation ELBO: 107.72547607421875\n",
      "epoch 13/20, train loss: 1.0667137098312378, validation MSE: 1.3374867200851441, validation ELBO: 103.46874542236328\n",
      "epoch 14/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 15/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 16/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 17/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 18/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 19/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 20/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "\n",
      "test MSE: nan, test ELBO: nan\n",
      "Parameter containing:\n",
      "tensor([[0.9069]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4559], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.1391]], device='cuda:0', requires_grad=True)\n",
      "Done                  \n",
      "\n",
      "epoch 1/20, train loss: 1.162881293296814, validation MSE: 3.967446708679199, validation ELBO: 143.1602783203125\n",
      "epoch 2/20, train loss: 1.2845766687393187, validation MSE: 8.41972312927246, validation ELBO: 130.81468200683594\n",
      "epoch 3/20, train loss: 1.239175410270691, validation MSE: 5.799268913269043, validation ELBO: 112.87146301269532\n",
      "epoch 4/20, train loss: 1.1200347566604614, validation MSE: 4.345866680145264, validation ELBO: 108.9439483642578\n",
      "epoch 5/20, train loss: 1.1648949813842773, validation MSE: 5.200017738342285, validation ELBO: 129.64165649414062\n",
      "epoch 6/20, train loss: 1.2892505073547362, validation MSE: 3.643504238128662, validation ELBO: 122.65021667480468\n",
      "epoch 7/20, train loss: 1.1783934903144837, validation MSE: 1.9550078868865968, validation ELBO: 110.95137786865234\n",
      "epoch 8/20, train loss: 1.1114644503593445, validation MSE: 3.8704872608184813, validation ELBO: 136.2548797607422\n",
      "epoch 9/20, train loss: 1.7801415348052978, validation MSE: 8.67180519104004, validation ELBO: 212.62499389648437\n",
      "epoch 10/20, train loss: 2.2004863357543947, validation MSE: 9.564332580566406, validation ELBO: 226.78919677734376\n",
      "epoch 11/20, train loss: 2.2738974285125733, validation MSE: 9.60545482635498, validation ELBO: 226.69227905273436\n",
      "epoch 12/20, train loss: 2.254722442626953, validation MSE: 9.341219711303712, validation ELBO: 222.52812805175782\n",
      "epoch 13/20, train loss: 2.1993744230270384, validation MSE: 9.061700057983398, validation ELBO: 216.08863830566406\n",
      "epoch 14/20, train loss: 2.1370422077178954, validation MSE: 8.746760177612305, validation ELBO: 208.95472412109376\n",
      "epoch 15/20, train loss: 2.062712025642395, validation MSE: 8.411327171325684, validation ELBO: 201.68960571289062\n",
      "epoch 16/20, train loss: 1.9847919321060181, validation MSE: 8.150898361206055, validation ELBO: 193.3456237792969\n",
      "epoch 17/20, train loss: 1.8982875680923461, validation MSE: 7.815487384796143, validation ELBO: 183.96964111328126\n",
      "epoch 18/20, train loss: 1.8046131658554077, validation MSE: 7.41379680633545, validation ELBO: 173.98131713867187\n",
      "epoch 19/20, train loss: 1.7004588985443114, validation MSE: 7.034380340576172, validation ELBO: 163.1079833984375\n",
      "epoch 20/20, train loss: 1.5856900644302367, validation MSE: 6.37262191772461, validation ELBO: 150.79063720703124\n",
      "\n",
      "test MSE: 4.465578079223633, test ELBO: 99.52782897949218\n",
      "Parameter containing:\n",
      "tensor([[0.8858]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.2663], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.7212]], device='cuda:0', requires_grad=True)\n",
      "Done                  \n",
      "\n",
      "epoch 1/20, train loss: 1.251591854095459, validation MSE: 2.392214632034302, validation ELBO: 121.43889770507812\n",
      "epoch 2/20, train loss: 1.1040991067886352, validation MSE: 1.5012288093566895, validation ELBO: 105.6943115234375\n",
      "epoch 3/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 4/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 5/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 6/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 7/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 8/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 9/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 10/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 11/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 12/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 13/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 14/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 15/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 16/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 17/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 18/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 19/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "epoch 20/20, train loss: nan, validation MSE: nan, validation ELBO: nan\n",
      "\n",
      "test MSE: nan, test ELBO: nan\n",
      "Parameter containing:\n",
      "tensor([[0.8469]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4186], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.7133]], device='cuda:0', requires_grad=True)\n",
      "Done                  \n",
      "\n",
      "epoch 1/20, train loss: 1.66712242603302, validation MSE: 5.7368487358093265, validation ELBO: 211.49342651367186\n",
      "epoch 2/20, train loss: 2.0810549545288084, validation MSE: 5.0251336097717285, validation ELBO: 195.6936462402344\n",
      "epoch 3/20, train loss: 1.7000772142410279, validation MSE: 3.9643366813659666, validation ELBO: 139.93811645507813\n",
      "epoch 4/20, train loss: 1.2960116410255431, validation MSE: 5.014600658416748, validation ELBO: 124.59147033691406\n",
      "epoch 5/20, train loss: 1.221362705230713, validation MSE: 2.0485440731048583, validation ELBO: 110.41504211425782\n",
      "epoch 6/20, train loss: 1.0515922284126282, validation MSE: 1.4856817722320557, validation ELBO: 103.17345275878907\n",
      "epoch 7/20, train loss: 1.665034475326538, validation MSE: 5.341050338745117, validation ELBO: 189.49138793945312\n",
      "epoch 8/20, train loss: 1.7528479433059692, validation MSE: 3.9485354900360106, validation ELBO: 154.8300354003906\n",
      "epoch 9/20, train loss: 1.4038680648803712, validation MSE: 2.517072629928589, validation ELBO: 122.24052429199219\n",
      "epoch 10/20, train loss: 1.2196283626556397, validation MSE: 3.478235960006714, validation ELBO: 118.61981353759765\n",
      "epoch 11/20, train loss: 1.1609282350540162, validation MSE: 1.6894015073776245, validation ELBO: 104.11756744384766\n",
      "epoch 12/20, train loss: 1.032044267654419, validation MSE: 1.476329255104065, validation ELBO: 103.02166442871093\n",
      "epoch 13/20, train loss: 1.0230635595321655, validation MSE: 1.3987035989761352, validation ELBO: 99.48455810546875\n",
      "epoch 14/20, train loss: 1.0217304062843322, validation MSE: 1.3577934503555298, validation ELBO: 100.20565338134766\n",
      "epoch 15/20, train loss: 1.0252470564842224, validation MSE: 1.3190398454666137, validation ELBO: 100.2907501220703\n",
      "epoch 16/20, train loss: 1.0224055123329163, validation MSE: 1.3274371862411498, validation ELBO: 100.11607360839844\n",
      "epoch 17/20, train loss: 1.0325487112998963, validation MSE: 1.376123070716858, validation ELBO: 101.31560363769532\n",
      "epoch 18/20, train loss: 1.0232718229293822, validation MSE: 1.2699396848678588, validation ELBO: 99.18203430175781\n",
      "epoch 19/20, train loss: 1.0639238739013672, validation MSE: 2.176930379867554, validation ELBO: 116.1381103515625\n",
      "epoch 20/20, train loss: 1.2472022104263305, validation MSE: 2.5034342288970945, validation ELBO: 126.0625244140625\n",
      "\n",
      "test MSE: 1.3090822219848632, test ELBO: 98.74990539550781\n",
      "Parameter containing:\n",
      "tensor([[0.8855]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.5184], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.2729]], device='cuda:0', requires_grad=True)\n",
      "Done                  \n",
      "\n",
      "epoch 1/20, train loss: 1.3741609621047974, validation MSE: 6.795030403137207, validation ELBO: 127.43217468261719\n",
      "epoch 2/20, train loss: 1.182764482498169, validation MSE: 3.523906135559082, validation ELBO: 112.57723388671874\n",
      "epoch 3/20, train loss: 1.1880317497253419, validation MSE: 2.824273633956909, validation ELBO: 116.51862182617188\n",
      "epoch 4/20, train loss: 1.1250303077697754, validation MSE: 1.5107440948486328, validation ELBO: 107.895361328125\n",
      "epoch 5/20, train loss: 1.163630645275116, validation MSE: 9.58134479522705, validation ELBO: 159.95303955078126\n",
      "epoch 6/20, train loss: 2.118548045158386, validation MSE: 26.251254653930665, validation ELBO: 250.75426025390624\n",
      "epoch 7/20, train loss: 2.6056128120422364, validation MSE: 30.44916229248047, validation ELBO: 268.63401184082034\n",
      "epoch 8/20, train loss: 2.706592149734497, validation MSE: 31.716009521484374, validation ELBO: 271.97593688964844\n",
      "epoch 9/20, train loss: 2.716319036483765, validation MSE: 32.36720352172851, validation ELBO: 270.514404296875\n",
      "epoch 10/20, train loss: 2.6918107318878173, validation MSE: 32.57486267089844, validation ELBO: 267.6842742919922\n",
      "epoch 11/20, train loss: 2.6604662322998047, validation MSE: 32.67744064331055, validation ELBO: 264.3437835693359\n",
      "epoch 12/20, train loss: 2.633594903945923, validation MSE: 32.7271484375, validation ELBO: 260.99744873046876\n",
      "epoch 13/20, train loss: 2.60049898147583, validation MSE: 32.79700241088867, validation ELBO: 257.2481384277344\n",
      "epoch 14/20, train loss: 2.565564670562744, validation MSE: 32.79058151245117, validation ELBO: 254.13413696289064\n",
      "epoch 15/20, train loss: 2.5292901229858398, validation MSE: 32.869293975830075, validation ELBO: 250.2908508300781\n",
      "epoch 16/20, train loss: 2.493686628341675, validation MSE: 32.84434814453125, validation ELBO: 247.1863525390625\n",
      "epoch 17/20, train loss: 2.4610329627990724, validation MSE: 32.83816070556641, validation ELBO: 243.29600219726564\n",
      "epoch 18/20, train loss: 2.422592420578003, validation MSE: 32.897515869140626, validation ELBO: 239.54699096679687\n",
      "epoch 19/20, train loss: 2.387479190826416, validation MSE: 32.86108245849609, validation ELBO: 236.121435546875\n",
      "epoch 20/20, train loss: 2.351211709976196, validation MSE: 32.80222091674805, validation ELBO: 232.8426300048828\n",
      "\n",
      "test MSE: 1.5187404870986938, test ELBO: 103.35511322021485\n",
      "Parameter containing:\n",
      "tensor([[0.8607]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4983], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.8402]], device='cuda:0', requires_grad=True)\n",
      "Done                  \n",
      "\n",
      "epoch 1/20, train loss: 1.4199993801116944, validation MSE: 7.750514125823974, validation ELBO: 159.76459350585938\n",
      "epoch 2/20, train loss: 1.563608808517456, validation MSE: 7.04620475769043, validation ELBO: 155.43594360351562\n",
      "epoch 3/20, train loss: 1.4213552951812745, validation MSE: 5.31274185180664, validation ELBO: 132.13824462890625\n",
      "epoch 4/20, train loss: 1.1733186531066895, validation MSE: 2.7363235473632814, validation ELBO: 109.33808898925781\n",
      "epoch 5/20, train loss: 1.2238248562812806, validation MSE: 4.484256172180176, validation ELBO: 164.97718811035156\n",
      "epoch 6/20, train loss: 1.65707754611969, validation MSE: 4.113994121551514, validation ELBO: 157.77868041992187\n",
      "epoch 7/20, train loss: 1.4273062753677368, validation MSE: 2.923274374008179, validation ELBO: 130.26043090820312\n",
      "epoch 8/20, train loss: 1.2191200208663941, validation MSE: 3.445706605911255, validation ELBO: 123.1523681640625\n",
      "epoch 9/20, train loss: 1.1434475231170653, validation MSE: 1.7476909637451172, validation ELBO: 109.72537231445312\n",
      "epoch 10/20, train loss: 1.0074144864082337, validation MSE: 1.4387372493743897, validation ELBO: 106.13160095214843\n",
      "epoch 11/20, train loss: 1.0031895232200623, validation MSE: 1.4485835313796998, validation ELBO: 104.83242340087891\n",
      "epoch 12/20, train loss: 1.2719179368019105, validation MSE: 5.565880012512207, validation ELBO: 202.705615234375\n",
      "epoch 13/20, train loss: 2.1599035978317263, validation MSE: 5.6423999786376955, validation ELBO: 227.15208129882814\n",
      "epoch 14/20, train loss: 2.270115623474121, validation MSE: 5.623661041259766, validation ELBO: 225.970361328125\n",
      "epoch 15/20, train loss: 2.1382261323928833, validation MSE: 4.845346450805664, validation ELBO: 194.53238830566406\n",
      "epoch 16/20, train loss: 1.7063089513778686, validation MSE: 4.703040409088135, validation ELBO: 139.0458740234375\n",
      "epoch 17/20, train loss: 1.250434594154358, validation MSE: 4.747729396820068, validation ELBO: 129.0396484375\n",
      "epoch 18/20, train loss: 1.2122635078430175, validation MSE: 2.449820327758789, validation ELBO: 114.6749267578125\n",
      "epoch 19/20, train loss: 1.0401755213737487, validation MSE: 1.4117561101913452, validation ELBO: 105.30595397949219\n",
      "epoch 20/20, train loss: 1.0060235905647277, validation MSE: 1.338281273841858, validation ELBO: 103.8652114868164\n",
      "\n",
      "test MSE: 1.3388523817062379, test ELBO: 98.87105560302734\n",
      "Parameter containing:\n",
      "tensor([[0.8742]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4395], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.1964]], device='cuda:0', requires_grad=True)\n",
      "Done                  \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 19\u001B[0m\n\u001B[0;32m     17\u001B[0m opt_schedule \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mlr_scheduler\u001B[38;5;241m.\u001B[39mExponentialLR(opt, \u001B[38;5;241m0.95\u001B[39m)\n\u001B[0;32m     18\u001B[0m dataset \u001B[38;5;241m=\u001B[39m pydpf\u001B[38;5;241m.\u001B[39mStateSpaceDataset(data_path, state_prefix\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstate\u001B[39m\u001B[38;5;124m'\u001B[39m, device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[1;32m---> 19\u001B[0m _, ELBO \u001B[38;5;241m=\u001B[39m train(dpf, opt, dataset, \u001B[38;5;241m20\u001B[39m, (\u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m100\u001B[39m), (\u001B[38;5;241m30\u001B[39m, \u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m100\u001B[39m), (\u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.25\u001B[39m, \u001B[38;5;241m0.25\u001B[39m), \u001B[38;5;241m1.\u001B[39m, experiment_cpu_rng, target\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mELBO\u001B[39m\u001B[38;5;124m'\u001B[39m, time_extent\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, lr_scheduler\u001B[38;5;241m=\u001B[39mopt_schedule)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28mprint\u001B[39m(alpha)\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(beta)\n",
      "File \u001B[1;32m~\\PycharmProjects\\dpf-baselining\\jss_examples\\Stochastic Volatility\\training_loop.py:66\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(dpf, opt, dataset, epochs, n_particles, batch_size, split_size, likelihood_scaling, data_loading_generator, gradient_regulariser, target, time_extent, lr_scheduler)\u001B[0m\n\u001B[0;32m     64\u001B[0m dpf\u001B[38;5;241m.\u001B[39mupdate()\n\u001B[0;32m     65\u001B[0m opt\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 66\u001B[0m loss \u001B[38;5;241m=\u001B[39m dpf(n_particles[\u001B[38;5;241m0\u001B[39m], time_extent, aggregation_function, observation\u001B[38;5;241m=\u001B[39mobservation, ground_truth\u001B[38;5;241m=\u001B[39mstate, gradient_regulariser \u001B[38;5;241m=\u001B[39m gradient_regulariser)\n\u001B[0;32m     67\u001B[0m loss \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean(loss[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mELBO\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m*\u001B[39mlikelihood_scaling \u001B[38;5;241m+\u001B[39m (\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m-\u001B[39mlikelihood_scaling)\u001B[38;5;241m*\u001B[39mtorch\u001B[38;5;241m.\u001B[39mmean(loss[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMSE\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     68\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\PycharmProjects\\dpf-baselining\\pydpf\\filtering.py:157\u001B[0m, in \u001B[0;36mSIS.forward\u001B[1;34m(self, n_particles, time_extent, aggregation_function, observation, gradient_regulariser, ground_truth, control, time, series_metadata)\u001B[0m\n\u001B[0;32m    155\u001B[0m prev_state \u001B[38;5;241m=\u001B[39m state\n\u001B[0;32m    156\u001B[0m prev_weight \u001B[38;5;241m=\u001B[39m weight\n\u001B[1;32m--> 157\u001B[0m state, weight, likelihood \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mproposal(prev_state \u001B[38;5;241m=\u001B[39m state, prev_weight \u001B[38;5;241m=\u001B[39m weight, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtime_data)\n\u001B[0;32m    158\u001B[0m likelihood \u001B[38;5;241m=\u001B[39m likelihood \u001B[38;5;241m-\u001B[39m log_N\n\u001B[0;32m    159\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m gradient_regulariser \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\dpf-baselining\\pydpf\\filtering.py:295\u001B[0m, in \u001B[0;36mParticleFilter._register_functions.<locals>.pf_sampler\u001B[1;34m(prev_state, prev_weight, **data)\u001B[0m\n\u001B[0;32m    294\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpf_sampler\u001B[39m(prev_state, prev_weight, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdata):\n\u001B[1;32m--> 295\u001B[0m     resampled_x, resampled_w \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresampler(prev_state, prev_weight, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdata)\n\u001B[0;32m    296\u001B[0m     state, weight \u001B[38;5;241m=\u001B[39m prop(prev_state\u001B[38;5;241m=\u001B[39mresampled_x, prev_weight\u001B[38;5;241m=\u001B[39mresampled_w, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdata)\n\u001B[0;32m    297\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\PycharmProjects\\dpf-baselining\\pydpf\\resampling.py:311\u001B[0m, in \u001B[0;36mOptimalTransportResampler.forward\u001B[1;34m(self, state, weight, **data)\u001B[0m\n\u001B[0;32m    309\u001B[0m N \u001B[38;5;241m=\u001B[39m state\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    310\u001B[0m log_b, cost, extent \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_sinkhorn_inputs_OT(N, weight, state)\n\u001B[1;32m--> 311\u001B[0m f, g, epsilon_used \u001B[38;5;241m=\u001B[39m optimal_transport\u001B[38;5;241m.\u001B[39msinkhorn_loop(weight, log_b, cost, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mregularisation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_update_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_iterations, extent\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_size)\n\u001B[0;32m    312\u001B[0m transport \u001B[38;5;241m=\u001B[39m optimal_transport\u001B[38;5;241m.\u001B[39mget_transport_from_potentials(weight, log_b, cost, f, g, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mregularisation)\n\u001B[0;32m    313\u001B[0m transport \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgradient_wrapper\u001B[38;5;241m.\u001B[39mapply(transport)\n",
      "File \u001B[1;32m~\\PycharmProjects\\dpf-baselining\\pydpf\\optimal_transport.py:151\u001B[0m, in \u001B[0;36msinkhorn_loop\u001B[1;34m(log_a, log_b, cost, epsilon, threshold, max_iter, diam, rate)\u001B[0m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m    150\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m stop_criterion(i, continue_criterion):\n\u001B[1;32m--> 151\u001B[0m         f_u \u001B[38;5;241m=\u001B[39m (f_i \u001B[38;5;241m+\u001B[39m opt_potential(log_b, g_i, cost, epsilon_now)) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m    152\u001B[0m         g_u \u001B[38;5;241m=\u001B[39m (g_i \u001B[38;5;241m+\u001B[39m opt_potential(log_a, f_i, cost_T, epsilon_now)) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m    153\u001B[0m         update_size \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmaximum(torch\u001B[38;5;241m.\u001B[39mabs(f_u \u001B[38;5;241m-\u001B[39m f_i), torch\u001B[38;5;241m.\u001B[39mabs(g_u \u001B[38;5;241m-\u001B[39m g_i))\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T11:01:24.301140400Z",
     "start_time": "2025-05-20T15:37:36.497050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result_path = pathlib.Path('.').parent.absolute().joinpath('multiple_parameters_results.csv')\n",
    "results = pd.read_csv(result_path, index_col=0)\n",
    "row = np.array([np.mean(ELBOs), np.mean(np.abs(alphas - 0.91)), np.mean(np.abs(betas - 0.5)), np.mean(np.abs(sigmas - 1.))])\n",
    "results.loc[DPF_type] = row\n",
    "print(results)\n",
    "results.to_csv(result_path)"
   ],
   "id": "e5d6c1f7af27be7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              ELBO  alpha error  beta error  sigma error\n",
      "method                                                                  \n",
      "DPF                     101.427136     0.013473    0.029280     0.027876\n",
      "Soft                    102.512920     0.020165    0.591598     0.108669\n",
      "Stop-Gradient           101.850480     0.008128    0.074635     0.036610\n",
      "Marginal Stop-Gradient  101.896044     0.007503    0.083038     0.049791\n",
      "Optimal Transport         0.000000     0.000000    0.000000     0.000000\n",
      "Kernel                  110.969481     0.044326    0.585970     0.733684\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
