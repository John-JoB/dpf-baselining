{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:31:22.921407Z",
     "start_time": "2025-05-16T10:31:21.222279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "from matplotlib import pyplot as plt\n",
    "import pydpf\n",
    "import torch\n",
    "from data_prep import prepare_data\n",
    "import model\n",
    "import neural_networks\n",
    "import training\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cuda_gen = torch.Generator(device=device).manual_seed(2)"
   ],
   "id": "1adc01df674ae529",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare data",
   "id": "869fe0978bc160fe"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-16T10:31:22.925694Z",
     "start_time": "2025-05-16T10:31:22.921407Z"
    }
   },
   "source": "#prepare_data('cuda:0')",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:31:22.970199Z",
     "start_time": "2025-05-16T10:31:22.967206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "observation_encoding_size = 128\n",
    "scaling = 1000."
   ],
   "id": "a1167460b876a853",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:31:22.979146Z",
     "start_time": "2025-05-16T10:31:22.973897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def flatten_gens(list_of_gens):\n",
    "    return [item for gen in list_of_gens for item in gen]\n",
    "    \n",
    "def is_in_it(item, it):\n",
    "    return any(id(item) == id(item_) for item_ in it)\n",
    "    \n",
    "\n",
    "def get_SSM():\n",
    "    encoder = neural_networks.ObservationEncoder(observation_encoding_size, generator=cuda_gen, dropout_keep_ratio=0.3)\n",
    "    decoder = neural_networks.ObservationDecoder(observation_encoding_size, generator=cuda_gen, dropout_keep_ratio=0.3)\n",
    "    state_encoder = neural_networks.StateEncoder(observation_encoding_size, generator=cuda_gen, dropout_keep_ratio=0.3)\n",
    "    observation_partial_flows = [neural_networks.RealNVP_cond(dim = observation_encoding_size, hidden_dim=observation_encoding_size, condition_on_dim=observation_encoding_size, generator = cuda_gen), neural_networks.RealNVP_cond(dim = observation_encoding_size, hidden_dim=observation_encoding_size, condition_on_dim=observation_encoding_size, generator = cuda_gen)]\n",
    "    flow_cov = torch.nn.Parameter(torch.eye(observation_encoding_size, device=device)*1000)\n",
    "    observation_flow = neural_networks.NormalizingFlowModel_cond(pydpf.MultivariateGaussian(torch.zeros(observation_encoding_size, device=device), cholesky_covariance= flow_cov, diagonal_cov=True, generator=cuda_gen), observation_partial_flows, device)\n",
    "    observation_model = model.MazeObservation(observation_flow, encoder, decoder, state_encoder)\n",
    "    #observation_model = model.SimpleMazeObservation(encoder, decoder, state_encoder)\n",
    "    dynamic_cov = torch.diag(torch.tensor([10/scaling, 10/scaling, 0.1], device=device))\n",
    "    dynamic_model = model.MazeDynamic(cuda_gen, dynamic_cov)\n",
    "    proposal_partial_flows = [neural_networks.RealNVP_cond(dim = 3, hidden_dim=32, condition_on_dim=observation_encoding_size, generator=cuda_gen, zero_i=True), neural_networks.RealNVP_cond(dim = 3, hidden_dim=32, condition_on_dim=observation_encoding_size, generator=cuda_gen, zero_i=True)]\n",
    "    proposal_flow = neural_networks.NormalizingFlowModel_cond(None, proposal_partial_flows, device)\n",
    "    proposal_model = model.MazeProposal(proposal_flow, dynamic_model)\n",
    "    prior_model = model.MazePrior(2*1000/scaling, 1.3*1000/scaling, cuda_gen)\n",
    "    #prior_model = model.MazePriorCheat()\n",
    "    encoder_parameters = flatten_gens([encoder.parameters(), state_encoder.parameters(), decoder.parameters()])\n",
    "    flow_parameters = flatten_gens([observation_flow.parameters(), proposal_flow.parameters(), prior_model.parameters()])\n",
    "    #SSM = pydpf.FilteringModel(dynamic_model=dynamic_model, proposal_model=proposal_model, prior_model=prior_model, observation_model=observation_model)\n",
    "    SSM = pydpf.FilteringModel(dynamic_model=dynamic_model, prior_model=prior_model, observation_model=observation_model)\n",
    "    return SSM, encoder_parameters, flow_parameters, [flow_cov]\n",
    "            "
   ],
   "id": "7b67079e3a4c7815",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:31:22.989140Z",
     "start_time": "2025-05-16T10:31:22.985300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def transform_control(control, **data):\n",
    "    output = control/torch.tensor([[[scaling, scaling, 1.]]], device=device)\n",
    "    return output\n",
    "    "
   ],
   "id": "5356bc7254f10704",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:31:23.005891Z",
     "start_time": "2025-05-16T10:31:23.003706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalise_obs(observation, **data):\n",
    "    return (observation - torch.mean(observation))/torch.std(observation)\n",
    "    "
   ],
   "id": "a24666d4fefec5c0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-16T10:31:23.010293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SSM, encoder_params, flow_params, flow_cov = get_SSM()\n",
    "dpf = pydpf.DPF(SSM=SSM, resampling_generator=cuda_gen)\n",
    "#dpf = pydpf.OptimalTransportDPF(SSM=SSM, regularisation=0.1, step_size=0.75)\n",
    "dpf.to(device)\n",
    "opt = torch.optim.AdamW([{'params': encoder_params, 'lr': 0.01}, {'params': flow_params, 'lr': 0.01}], weight_decay=1e-4)\n",
    "opt_scheduler = torch.optim.lr_scheduler.ExponentialLR(opt, gamma=0.95)\n",
    "data = pydpf.StateSpaceDataset(data_path= pathlib.Path('.').parent.absolute().joinpath('data/maze_data.csv'), state_prefix='state', control_prefix='control', device = device)\n",
    "data.apply(normalise_obs,  'observation')\n",
    "scaling_tesnor = torch.tensor([[[scaling, scaling, 1.]]], device=device)\n",
    "data.apply(lambda state, **data: (state - torch.tensor([[[1000., 650., 0.]]], device=device))/scaling_tesnor, 'state')\n",
    "data.apply(transform_control, 'control')\n",
    "print('Data Loaded')\n",
    "training.train(dpf, opt, data, 100, (100, 1000, 1000), (64, 64, 32), (0.45, 0.2, 0.35), (10., 1., 2.), torch.Generator().manual_seed(0), None, 'MSE', 99, pre_train_epochs=0, device=device, lr_scheduler=opt_scheduler, state_scaling = scaling)\n"
   ],
   "id": "262e79dca2f4d309",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded\n",
      "epoch 1/100, train loss: 14.752500415378147, validation position RMSE: 1519.5460769585106, validation angle RMSE: 1.823504470079161\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:31:57.111868Z",
     "start_time": "2025-05-16T10:31:56.845907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "obs = data.observation[:, 1000:1001]\n",
    "state = data.state[:, 1000:1001]\n",
    "print(state[0])\n",
    "control = data.control[:, 1000:1001]\n",
    "time = 99\n",
    "batch = 0\n",
    "encoded_obs = SSM.observation_model.encoder(obs.reshape(obs.size(0)*obs.size(1), 3, 24, 24))\n",
    "dpf.update()\n",
    "with torch.inference_mode():\n",
    "    ps = dpf(1000, 99, {'state': pydpf.State(), 'weight': pydpf.Weight()}, observation=encoded_obs.reshape(100, 1, encoded_obs.size(1)).contiguous(), ground_truth=state, control=control)\n",
    "numpy_ps = ps['state'].detach().cpu().numpy()\n",
    "\n",
    "numpy_weight = ps['weight'].detach().cpu().numpy()\n",
    "print(numpy_weight[0])\n",
    "numpy_weight_norm = (np.exp(numpy_weight) / np.sum(np.exp(numpy_weight), axis=-1, keepdims=True))[:,0,:]\n",
    "#print(numpy_weight[0, 0, :])\n",
    "plt.scatter(numpy_ps[time,batch,:,0]*scaling, numpy_ps[time,batch,:,1]*scaling, alpha=np.exp(numpy_weight[time, batch, :])/np.max(np.exp(numpy_weight[time, batch, :])))\n",
    "plt.scatter(state.cpu().numpy()[time,batch,0]*scaling, state.cpu().numpy()[time,batch,1]*scaling)\n",
    "plt.scatter(np.sum(numpy_ps[time,batch,:,0]*numpy_weight_norm[time], keepdims=True)*scaling, [np.sum(numpy_ps[time,batch,:,1]*numpy_weight_norm[time], keepdims=True)*scaling], color='red')\n",
    "plt.xlim(-1000, 1000)\n",
    "plt.ylim(-650, 650)\n",
    "plt.show()"
   ],
   "id": "eb2438f3cc2aedb7",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m obs \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mobservation[:, \u001B[38;5;241m1000\u001B[39m:\u001B[38;5;241m1001\u001B[39m]\n\u001B[0;32m      2\u001B[0m state \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mstate[:, \u001B[38;5;241m1000\u001B[39m:\u001B[38;5;241m1001\u001B[39m]\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(state[\u001B[38;5;241m0\u001B[39m])\n",
      "\u001B[1;31mNameError\u001B[0m: name 'data' is not defined"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
