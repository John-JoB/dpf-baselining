{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-22T14:52:09.619572Z",
     "start_time": "2025-01-22T14:52:09.612463Z"
    }
   },
   "source": [
    "import pydpf\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from typing import Tuple, Union\n",
    "from pydpf.datautils import StateSpaceDataset\n",
    "\n",
    "from pydpf.distributions.Gaussian import MultivariateGaussian, LinearGaussian\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import training\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "data_folder =  Path('./data/test/')"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:52:09.632254Z",
     "start_time": "2025-01-22T14:52:09.627044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gen_num = 9\n",
    "def new_gen():\n",
    "    global gen_num\n",
    "    global device\n",
    "    gen_num += 1\n",
    "    return torch.Generator(device=device).manual_seed(gen_num)\n",
    "\n",
    "def get_spectral_radius(M):\n",
    "    eigvals = torch.linalg.eigvals(M)\n",
    "    return torch.max(torch.abs(eigvals))\n",
    "\n",
    "def make_random(size, range, sparsity, device, generator):\n",
    "    return torch.where(torch.rand(size, device=device, generator=generator) < sparsity, torch.rand(size, device=device, generator=generator) * (range[1] - range[0]) + range[0], 0) \n",
    "\n",
    "def make_random_matrix(*, data:Tensor=None, device:torch.device=None, force_diagonal:bool=False, size:Union[Tuple[int,int], int]=None, range:Tuple[float,float]=(0.,1.), diag_range:Tuple[float,float]=(0.,1.), off_diag_range:Tuple[float,float]=(0., 1.), max_radius:float=None, generator:torch.Generator=None, positive_definite:bool=False, requires_grad:bool = True, sparsity:float=1.):\n",
    "    if generator is None:\n",
    "        generator = torch.Generator(device=device)\n",
    "    if not data is None:\n",
    "        return torch.nn.Parameter(data, requires_grad)\n",
    "    if isinstance(size, int):\n",
    "        vec = make_random(size, range, sparsity, device, generator)\n",
    "        return torch.nn.Parameter(vec, requires_grad)\n",
    "    if size[0]==size[1]:\n",
    "        if positive_definite and diag_range[0]<0:\n",
    "            raise ValueError(\"Diagonal range must be positive for positive definite matrices\")\n",
    "        \n",
    "        diag = make_random(size[0], diag_range, sparsity, device, generator)\n",
    "        matrix = torch.diag(diag)\n",
    "        if not force_diagonal:\n",
    "            off_diag = make_random(size, off_diag_range, sparsity, device, generator) * (1-torch.eye(size[0], device=device))\n",
    "            matrix += off_diag\n",
    "            if positive_definite:\n",
    "                matrix = matrix.T @ matrix\n",
    "        if max_radius is not None:\n",
    "            radius = get_spectral_radius(matrix)\n",
    "            if radius > max_radius:\n",
    "                raise ValueError(f'Spectral radius {radius} exceeds maximum {max_radius}, consider decreasing the range or trying a different seed')\n",
    "        return torch.nn.Parameter(matrix, requires_grad)\n",
    "            \n",
    "    matrix = make_random(size, range, sparsity, device, generator)\n",
    "    return torch.nn.Parameter(matrix, requires_grad)\n",
    "\n",
    "def load_matrix_csv(path, name):\n",
    "    matrix_loc = path / name\n",
    "    return torch.tensor(np.loadtxt(matrix_loc, delimiter=','), device=device, dtype=torch.float32)\n",
    "    "
   ],
   "id": "d2e6bac920c53fd1",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:52:10.087661Z",
     "start_time": "2025-01-22T14:52:09.710699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_loc = data_folder / 'data.csv'\n",
    "normalise = True\n",
    "\n",
    "data_set = StateSpaceDataset(data_loc, state_prefix='state', device=device)\n",
    "initialisation_generator = new_gen()"
   ],
   "id": "62202735057694ee",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:52:10.170419Z",
     "start_time": "2025-01-22T14:52:10.157955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prior_covariance = make_random_matrix(size = (data_set.state_dimension, data_set.state_dimension), diag_range=(0, 1), off_diag_range=(-1, 1), generator=initialisation_generator, device=device, positive_definite=True)\n",
    "dynamic_matrix = make_random_matrix(size=(data_set.state_dimension,data_set.state_dimension), diag_range=(-0.2, 0.2), off_diag_range=(-0.3, 0.3), generator=initialisation_generator, max_radius=1, device=device)\n",
    "dynamic_bias = make_random_matrix(size=data_set.state_dimension, range=(-0.3, 0.3), generator=initialisation_generator, device=device, requires_grad=False)\n",
    "dynamic_covariance = make_random_matrix(size = (data_set.state_dimension, data_set.state_dimension), diag_range=(0, 1), off_diag_range=(-1, 1), generator=initialisation_generator, device=device, positive_definite=True)\n",
    "if data_set.state_dimension==data_set.observation_dimension:\n",
    "    observation_matrix = make_random_matrix(size=(data_set.observation_dimension,data_set.state_dimension), diag_range=(-1, 1), off_diag_range=(-1, 1), generator=initialisation_generator, device=device)\n",
    "else:\n",
    "    observation_matrix = make_random_matrix(size=(data_set.observation_dimension,data_set.state_dimension), range=(-1, 1), generator=initialisation_generator, device=device)\n",
    "observation_bias = make_random_matrix(size=data_set.state_dimension, range=(-1, 1), generator=initialisation_generator, device=device)\n",
    "observation_covariance = make_random_matrix(size = (data_set.observation_dimension, data_set.observation_dimension), diag_range=(0, 1), off_diag_range=(-1, 1), generator=initialisation_generator, device=device, positive_definite=True)\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "d1de389645530f16",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:52:10.259447Z",
     "start_time": "2025-01-22T14:52:10.247590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "kernel = pydpf.KernelMixture([('Gaussian', 5)], gradient_estimator='none', generator=new_gen())\n",
    "prior_covariance = prior_covariance\n",
    "v, x = (torch.linalg.eigh(prior_covariance))\n",
    "prior_covariance.data = torch.linalg.cholesky(prior_covariance).detach()\n",
    "dynamic_covariance.data = torch.linalg.cholesky(dynamic_covariance).detach()\n",
    "observation_covariance = torch.linalg.cholesky(observation_covariance).detach()\n",
    "prior_dist = MultivariateGaussian(mean = torch.zeros(data_set.state_dimension, device = device), cholesky_covariance=prior_covariance, generator=new_gen())\n",
    "dynamic_dist = LinearGaussian(weight = dynamic_matrix, bias = dynamic_bias, cholesky_covariance=dynamic_covariance, generator=new_gen(), constrain_spectral_radius=0.99)\n",
    "observation_dist = LinearGaussian(weight = observation_matrix, bias = observation_bias, cholesky_covariance=observation_covariance, generator=new_gen())\n",
    "SSM = pydpf.FilteringModel(dynamic_model=dynamic_dist, observation_model=observation_dist, prior_model=prior_dist)\n",
    "dpf = pydpf.KernelDPF(SSM, kernel)"
   ],
   "id": "be8d4bf7e4d20ebb",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:53:19.692090700Z",
     "start_time": "2025-01-22T14:51:52.598280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prior_covariance = load_matrix_csv(data_folder, 'prior_covariance.csv')\n",
    "dynamic_covariance = load_matrix_csv(data_folder, 'dynamic_covariance.csv')\n",
    "dynamic_bias = load_matrix_csv(data_folder, 'dynamic_bias.csv')\n",
    "dynamic_matrix = load_matrix_csv(data_folder, 'dynamic_matrix.csv')\n",
    "observation_bias = load_matrix_csv(data_folder, 'observation_bias.csv')\n",
    "observation_covariance = load_matrix_csv(data_folder, 'observation_covariance.csv')\n",
    "observation_matrix = load_matrix_csv(data_folder, 'observation_matrix.csv')\n",
    "prior_dist = MultivariateGaussian(mean = torch.zeros(data_set.state_dimension, device = device), cholesky_covariance=torch.linalg.cholesky(prior_covariance), generator=new_gen())\n",
    "dynamic_dist = LinearGaussian(weight = dynamic_matrix, bias = dynamic_bias, cholesky_covariance=torch.linalg.cholesky(dynamic_covariance), generator=new_gen(), constrain_spectral_radius=0.99)\n",
    "observation_dist = LinearGaussian(weight = observation_matrix, bias = observation_bias, cholesky_covariance=torch.linalg.cholesky(observation_covariance), generator=new_gen())\n",
    "SSM = pydpf.FilteringModel(dynamic_model=dynamic_dist, observation_model=observation_dist, prior_model=prior_dist)\n",
    "pf = pydpf.DPF(SSM, resampling_generator=new_gen())"
   ],
   "id": "26a61177636dfaa5",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:53:19.692090700Z",
     "start_time": "2025-01-22T14:51:52.663040Z"
    }
   },
   "cell_type": "code",
   "source": "training.test(pf, data_set, 1000, 20,  pydpf.MSE_Loss(), data_loading_generator=torch.Generator().manual_seed(10))",
   "id": "54508f4c10ecbf81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m training\u001B[38;5;241m.\u001B[39mtest(pf, data_set, \u001B[38;5;241m1000\u001B[39m, \u001B[38;5;241m20\u001B[39m,  pydpf\u001B[38;5;241m.\u001B[39mMSE_Loss(), data_loading_generator\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mGenerator()\u001B[38;5;241m.\u001B[39mmanual_seed(\u001B[38;5;241m10\u001B[39m))\n",
      "File \u001B[1;32m~\\PycharmProjects\\dpf-baselining\\Linear Gaussian\\training.py:40\u001B[0m, in \u001B[0;36mtest\u001B[1;34m(pf, data, n_particles, batch_size, loss_function, data_loading_generator)\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m state, observation \u001B[38;5;129;01min\u001B[39;00m loader:\n\u001B[0;32m     39\u001B[0m     pf\u001B[38;5;241m.\u001B[39mupdate()\n\u001B[1;32m---> 40\u001B[0m     loss \u001B[38;5;241m=\u001B[39m pf(n_particles, observation\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m, loss_function, observation\u001B[38;5;241m=\u001B[39mobservation, ground_truth\u001B[38;5;241m=\u001B[39mstate, gradient_regulariser \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     41\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mmean()\n\u001B[0;32m     42\u001B[0m     losses\u001B[38;5;241m.\u001B[39mappend(loss\u001B[38;5;241m.\u001B[39mitem()\u001B[38;5;241m*\u001B[39mstate\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m1\u001B[39m))\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\PycharmProjects\\dpf-baselining\\pydpf\\filtering.py:136\u001B[0m, in \u001B[0;36mSIS.forward\u001B[1;34m(self, n_particles, time_extent, aggregation_function, observation, gradient_regulariser, ground_truth, control, time, series_metadata)\u001B[0m\n\u001B[0;32m    134\u001B[0m     state, weight \u001B[38;5;241m=\u001B[39m gradient_regulariser(state \u001B[38;5;241m=\u001B[39m state, weight \u001B[38;5;241m=\u001B[39m weight, prev_state\u001B[38;5;241m=\u001B[39m prev_state, prev_weight \u001B[38;5;241m=\u001B[39m prev_weight)\n\u001B[0;32m    135\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m gt_exists:\n\u001B[1;32m--> 136\u001B[0m     output[t] \u001B[38;5;241m=\u001B[39m aggregation_function(state\u001B[38;5;241m=\u001B[39mstate, weight\u001B[38;5;241m=\u001B[39mweight, likelihood\u001B[38;5;241m=\u001B[39mlikelihood, ground_truth \u001B[38;5;241m=\u001B[39m ground_truth[t], \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtime_data)\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    138\u001B[0m     output[t] \u001B[38;5;241m=\u001B[39m aggregation_function(state\u001B[38;5;241m=\u001B[39mstate, weight\u001B[38;5;241m=\u001B[39mweight, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtime_data)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1732\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1729\u001B[0m             tracing_state\u001B[38;5;241m.\u001B[39mpop_scope()\n\u001B[0;32m   1730\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[1;32m-> 1732\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_wrapped_call_impl\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   1733\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1734\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
